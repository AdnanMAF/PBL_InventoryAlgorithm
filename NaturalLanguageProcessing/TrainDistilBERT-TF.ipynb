{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "4a36df14",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "g:\\Apps\\Anaconda\\envs\\tf-gpu\\lib\\site-packages\\tqdm\\auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "from sklearn.utils.class_weight import compute_class_weight\n",
    "from transformers import DistilBertTokenizer, TFDistilBertForSequenceClassification"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "fda83505",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 1) Load your balanced CSV\n",
    "df = pd.read_csv(\"../Data/NLP/news_sentiment_balanced.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "075f6c1d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 2) Rebuild a single 'text' column from your cleaned fields\n",
    "#    (adjust column names if yours differ)\n",
    "df[\"text\"] = (\n",
    "    df[\"title_clean\"].fillna(\"\") + \" \"\n",
    "  + df[\"description_clean\"].fillna(\"\") + \" \"\n",
    "  + df[\"content_clean\"].fillna(\"\")\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "2bb9dc62",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 3) Encode sentiment labels to integers\n",
    "le = LabelEncoder()\n",
    "df[\"label\"] = le.fit_transform(df[\"sentiment\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "d5363003",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 4) Stratified train/validation split\n",
    "train_texts, val_texts, train_labels, val_labels = train_test_split(\n",
    "    df[\"text\"].tolist(),\n",
    "    df[\"label\"].tolist(),\n",
    "    test_size=0.2,\n",
    "    stratify=df[\"label\"],\n",
    "    random_state=42\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "f6510d24",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 5) Compute class weights on the training labels\n",
    "weights = compute_class_weight(\n",
    "    class_weight=\"balanced\",\n",
    "    classes=np.unique(train_labels),\n",
    "    y=train_labels\n",
    ")\n",
    "class_weight_dict = dict(enumerate(weights))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "7a43cafd",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "g:\\Apps\\Anaconda\\envs\\tf-gpu\\lib\\site-packages\\huggingface_hub\\file_download.py:943: FutureWarning: `resume_download` is deprecated and will be removed in version 1.0.0. Downloads always resume when possible. If you want to force a new download, use `force_download=True`.\n",
      "  warnings.warn(\n"
     ]
    }
   ],
   "source": [
    "# 6) Tokenize with DistilBERT tokenizer\n",
    "tokenizer = DistilBertTokenizer.from_pretrained(\"distilbert-base-uncased\")\n",
    "train_enc = tokenizer(train_texts, truncation=True, padding=True, max_length=64)\n",
    "val_enc   = tokenizer(val_texts,   truncation=True, padding=True, max_length=64)\n",
    "\n",
    "def to_tf_dataset(encodings, labels):\n",
    "    return tf.data.Dataset.from_tensor_slices((\n",
    "        dict(encodings),\n",
    "        tf.convert_to_tensor(labels)\n",
    "    ))\n",
    "\n",
    "train_ds = to_tf_dataset(train_enc, train_labels).shuffle(1000).batch(8)\n",
    "val_ds   = to_tf_dataset(val_enc,   val_labels).batch(8)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "5b202ca6",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of the PyTorch model were not used when initializing the TF 2.0 model TFDistilBertForSequenceClassification: ['vocab_layer_norm.bias', 'vocab_projector.bias', 'vocab_layer_norm.weight', 'vocab_transform.bias', 'vocab_transform.weight']\n",
      "- This IS expected if you are initializing TFDistilBertForSequenceClassification from a PyTorch model trained on another task or with another architecture (e.g. initializing a TFBertForSequenceClassification model from a BertForPreTraining model).\n",
      "- This IS NOT expected if you are initializing TFDistilBertForSequenceClassification from a PyTorch model that you expect to be exactly identical (e.g. initializing a TFBertForSequenceClassification model from a BertForSequenceClassification model).\n",
      "Some weights or buffers of the TF 2.0 model TFDistilBertForSequenceClassification were not initialized from the PyTorch model and are newly initialized: ['pre_classifier.weight', 'pre_classifier.bias', 'classifier.weight', 'classifier.bias']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    }
   ],
   "source": [
    "# 7) Load and compile DistilBERT for classification\n",
    "model = TFDistilBertForSequenceClassification.from_pretrained(\n",
    "    \"distilbert-base-uncased\",\n",
    "    num_labels=len(le.classes_)\n",
    ")\n",
    "\n",
    "model.compile(\n",
    "    optimizer=tf.keras.optimizers.Adam(learning_rate=2e-5),\n",
    "    loss=tf.keras.losses.SparseCategoricalCrossentropy(from_logits=True),\n",
    "    metrics=[\"accuracy\"]\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "cf3b4e96",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/10\n",
      "17/17 [==============================] - 13s 235ms/step - loss: 1.0975 - accuracy: 0.1970 - val_loss: 1.0825 - val_accuracy: 0.2727\n",
      "Epoch 2/10\n",
      "17/17 [==============================] - 3s 148ms/step - loss: 1.0245 - accuracy: 0.6742 - val_loss: 0.9944 - val_accuracy: 0.6364\n",
      "Epoch 3/10\n",
      "17/17 [==============================] - 2s 146ms/step - loss: 0.8666 - accuracy: 0.8409 - val_loss: 0.8465 - val_accuracy: 0.7273\n",
      "Epoch 4/10\n",
      "17/17 [==============================] - 2s 145ms/step - loss: 0.6134 - accuracy: 0.9470 - val_loss: 0.6800 - val_accuracy: 0.8182\n",
      "Epoch 5/10\n",
      "17/17 [==============================] - 2s 146ms/step - loss: 0.3629 - accuracy: 1.0000 - val_loss: 0.4400 - val_accuracy: 0.8788\n",
      "Epoch 6/10\n",
      "17/17 [==============================] - 2s 145ms/step - loss: 0.1927 - accuracy: 1.0000 - val_loss: 0.3440 - val_accuracy: 0.8485\n",
      "Epoch 7/10\n",
      "17/17 [==============================] - 2s 145ms/step - loss: 0.0980 - accuracy: 1.0000 - val_loss: 0.3391 - val_accuracy: 0.8485\n",
      "Epoch 8/10\n",
      "17/17 [==============================] - 2s 137ms/step - loss: 0.0636 - accuracy: 1.0000 - val_loss: 0.3524 - val_accuracy: 0.8485\n",
      "Epoch 9/10\n",
      "17/17 [==============================] - 2s 141ms/step - loss: 0.0437 - accuracy: 1.0000 - val_loss: 0.3550 - val_accuracy: 0.8485\n"
     ]
    }
   ],
   "source": [
    "# 8) Train with EarlyStopping and class weights\n",
    "early_stop = tf.keras.callbacks.EarlyStopping(\n",
    "    monitor=\"val_loss\", patience=2, restore_best_weights=True\n",
    ")\n",
    "\n",
    "history = model.fit(\n",
    "    train_ds,\n",
    "    validation_data=val_ds,\n",
    "    epochs=10,\n",
    "    callbacks=[early_stop],\n",
    "    class_weight=class_weight_dict\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "3c0a6bfc",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "('./Models/saved_model_distilbert_balanced\\\\tokenizer_config.json',\n",
       " './Models/saved_model_distilbert_balanced\\\\special_tokens_map.json',\n",
       " './Models/saved_model_distilbert_balanced\\\\vocab.txt',\n",
       " './Models/saved_model_distilbert_balanced\\\\added_tokens.json')"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 9) Save your fine-tuned model & tokenizer\n",
    "model.save_pretrained(\"./Models/saved_model_distilbert_balanced\")\n",
    "tokenizer.save_pretrained(\"./Models/saved_model_distilbert_balanced\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "tf-gpu",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.22"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
