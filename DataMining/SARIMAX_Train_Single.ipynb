{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "3f50f748",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import warnings\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from statsmodels.tsa.stattools import adfuller\n",
    "from statsmodels.tsa.statespace.sarimax import SARIMAX\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.metrics import mean_squared_error, mean_absolute_error, r2_score\n",
    "from pmdarima import auto_arima\n",
    "\n",
    "# Suppress warnings from statsmodels and pmdarima\n",
    "warnings.filterwarnings(\"ignore\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "1056b881",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "→ Modeling only family = 'AUTOMOTIVE'\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# ─────────── USER CONFIG ────────────────────────────────────────────────────────\n",
    "# 1) Choose a single family to model (replace with any family string from train.csv)\n",
    "FAMILY = \"AUTOMOTIVE\"\n",
    "\n",
    "# 2) File paths (adjust if needed)\n",
    "TRAIN_CSV = \"../Data/DM/train.csv\"   # Must contain: [id, date, store_nbr, family, sales, onpromotion]\n",
    "TEST_CSV  = \"../Data/DM/test.csv\"    # Must contain: [id, date, store_nbr, family, onpromotion]\n",
    "\n",
    "# 3) Output filenames for this family\n",
    "PERF_CSV     = f\"performance_{FAMILY.replace(' ', '_')}.csv\"\n",
    "FORECAST_CSV = f\"forecast_{FAMILY.replace(' ', '_')}.csv\"\n",
    "\n",
    "# 4) Hold-out size (set to 0 to skip hold-out)\n",
    "N_VALID = 14\n",
    "\n",
    "# 5) Time-series frequency\n",
    "FREQ = \"D\"  # daily\n",
    "\n",
    "# 6) auto_arima arguments\n",
    "AUTO_ARIMA_ARGS = {\n",
    "    \"seasonal\": True,\n",
    "    \"m\": 7,  # weekly seasonality\n",
    "    \"start_p\": 0, \"start_q\": 0, \"max_p\": 5, \"max_q\": 5,\n",
    "    \"start_P\": 0, \"start_Q\": 0, \"max_P\": 2, \"max_Q\": 2,\n",
    "    \"d\": None, \"D\": None,\n",
    "    \"trace\": False,\n",
    "    \"error_action\": \"ignore\",\n",
    "    \"suppress_warnings\": True,\n",
    "    \"stepwise\": True,\n",
    "    \"information_criterion\": \"aic\"\n",
    "}\n",
    "\n",
    "print(f\"→ Modeling only family = '{FAMILY}'\\n\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "d8aa7ea3",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Helper: ADF stationarity test\n",
    "def test_stationarity(ts, name=\"series\"):\n",
    "    \"\"\"\n",
    "    Perform the Augmented Dickey-Fuller test on a 1D series `ts`.\n",
    "    Prints ADF statistic, p-value, and critical values.\n",
    "    \"\"\"\n",
    "    result = adfuller(ts)\n",
    "    print(\"  ─\" * 30)\n",
    "    print(f\"  ADF Statistic ({name}): {result[0]:.5f}\")\n",
    "    print(f\"  p-value:            {result[1]:.5f}\")\n",
    "    for key, val in result[4].items():\n",
    "        print(f\"  Critical Value ({key}): {val:.5f}\")\n",
    "    if result[1] < 0.05:\n",
    "        print(\"  → The series IS stationary (reject H₀).\")\n",
    "    else:\n",
    "        print(\"  → The series is NOT stationary (fail to reject H₀).\")\n",
    "    print(\"  ─\" * 30)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "e36719b9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Removed 1 zero-sales rows → 1683 remaining\n",
      "Held out last 14 days for validation.\n",
      "\n",
      "Running ADF test on training 'sales' series:\n",
      "  ─  ─  ─  ─  ─  ─  ─  ─  ─  ─  ─  ─  ─  ─  ─  ─  ─  ─  ─  ─  ─  ─  ─  ─  ─  ─  ─  ─  ─  ─\n",
      "  ADF Statistic (sales): -3.16413\n",
      "  p-value:            0.02216\n",
      "  Critical Value (1%): -3.43433\n",
      "  Critical Value (5%): -2.86330\n",
      "  Critical Value (10%): -2.56771\n",
      "  → The series IS stationary (reject H₀).\n",
      "  ─  ─  ─  ─  ─  ─  ─  ─  ─  ─  ─  ─  ─  ─  ─  ─  ─  ─  ─  ─  ─  ─  ─  ─  ─  ─  ─  ─  ─  ─\n",
      "\n",
      "Running auto_arima for hyperparameter tuning:\n",
      "Selected order = (0, 1, 2), seasonal_order = (1, 0, 1, 7)\n",
      "\n",
      "Fitting SARIMAX on log-transformed series with scaled exogenous:\n",
      "                                      SARIMAX Results                                      \n",
      "===========================================================================================\n",
      "Dep. Variable:                               y_log   No. Observations:                 1669\n",
      "Model:             SARIMAX(0, 1, 2)x(1, 0, [1], 7)   Log Likelihood                -255.311\n",
      "Date:                             Wed, 04 Jun 2025   AIC                            522.621\n",
      "Time:                                     19:15:08   BIC                            555.101\n",
      "Sample:                                 01-02-2013   HQIC                           534.661\n",
      "                                      - 08-01-2017                                         \n",
      "Covariance Type:                               opg                                         \n",
      "==============================================================================\n",
      "                 coef    std err          z      P>|z|      [0.025      0.975]\n",
      "------------------------------------------------------------------------------\n",
      "0              0.0361      0.013      2.686      0.007       0.010       0.062\n",
      "ma.L1         -0.9148      0.012    -75.348      0.000      -0.939      -0.891\n",
      "ma.L2         -0.0662      0.012     -5.365      0.000      -0.090      -0.042\n",
      "ar.S.L7        0.9796      0.007    144.235      0.000       0.966       0.993\n",
      "ma.S.L7       -0.8565      0.015    -56.477      0.000      -0.886      -0.827\n",
      "sigma2         0.0790      0.001    115.979      0.000       0.078       0.080\n",
      "===================================================================================\n",
      "Ljung-Box (L1) (Q):                   0.00   Jarque-Bera (JB):           1502689.14\n",
      "Prob(Q):                              0.98   Prob(JB):                         0.00\n",
      "Heteroskedasticity (H):               1.13   Skew:                            -9.11\n",
      "Prob(H) (two-sided):                  0.16   Kurtosis:                       149.36\n",
      "===================================================================================\n",
      "\n",
      "Warnings:\n",
      "[1] Covariance matrix calculated using the outer product of gradients (complex-step).\n",
      "\n",
      "Computing hold-out metrics:\n",
      "Hold‐out metrics:\n",
      "  RMSE = 58.11\n",
      "   MAE = 44.71\n",
      "    R² = 0.498\n",
      "  MAPE = 10.81%\n",
      "Hold-out performance saved to performance_AUTOMOTIVE.csv\n",
      "\n",
      "Forecasting 16 future points on test set:\n",
      "Forecasts saved to forecast_AUTOMOTIVE.csv\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>date</th>\n",
       "      <th>store_nbr</th>\n",
       "      <th>family</th>\n",
       "      <th>predicted_sales</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>3000888</td>\n",
       "      <td>2017-08-16</td>\n",
       "      <td>1</td>\n",
       "      <td>AUTOMOTIVE</td>\n",
       "      <td>319.714096</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>3000921</td>\n",
       "      <td>2017-08-16</td>\n",
       "      <td>10</td>\n",
       "      <td>AUTOMOTIVE</td>\n",
       "      <td>319.714096</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>3000954</td>\n",
       "      <td>2017-08-16</td>\n",
       "      <td>11</td>\n",
       "      <td>AUTOMOTIVE</td>\n",
       "      <td>319.714096</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>3000987</td>\n",
       "      <td>2017-08-16</td>\n",
       "      <td>12</td>\n",
       "      <td>AUTOMOTIVE</td>\n",
       "      <td>319.714096</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>3001020</td>\n",
       "      <td>2017-08-16</td>\n",
       "      <td>13</td>\n",
       "      <td>AUTOMOTIVE</td>\n",
       "      <td>319.714096</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>3001053</td>\n",
       "      <td>2017-08-16</td>\n",
       "      <td>14</td>\n",
       "      <td>AUTOMOTIVE</td>\n",
       "      <td>319.714096</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>3001086</td>\n",
       "      <td>2017-08-16</td>\n",
       "      <td>15</td>\n",
       "      <td>AUTOMOTIVE</td>\n",
       "      <td>319.714096</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>3001119</td>\n",
       "      <td>2017-08-16</td>\n",
       "      <td>16</td>\n",
       "      <td>AUTOMOTIVE</td>\n",
       "      <td>319.714096</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>3001152</td>\n",
       "      <td>2017-08-16</td>\n",
       "      <td>17</td>\n",
       "      <td>AUTOMOTIVE</td>\n",
       "      <td>319.714096</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>3001185</td>\n",
       "      <td>2017-08-16</td>\n",
       "      <td>18</td>\n",
       "      <td>AUTOMOTIVE</td>\n",
       "      <td>319.714096</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "        id       date  store_nbr      family  predicted_sales\n",
       "0  3000888 2017-08-16          1  AUTOMOTIVE       319.714096\n",
       "1  3000921 2017-08-16         10  AUTOMOTIVE       319.714096\n",
       "2  3000954 2017-08-16         11  AUTOMOTIVE       319.714096\n",
       "3  3000987 2017-08-16         12  AUTOMOTIVE       319.714096\n",
       "4  3001020 2017-08-16         13  AUTOMOTIVE       319.714096\n",
       "5  3001053 2017-08-16         14  AUTOMOTIVE       319.714096\n",
       "6  3001086 2017-08-16         15  AUTOMOTIVE       319.714096\n",
       "7  3001119 2017-08-16         16  AUTOMOTIVE       319.714096\n",
       "8  3001152 2017-08-16         17  AUTOMOTIVE       319.714096\n",
       "9  3001185 2017-08-16         18  AUTOMOTIVE       319.714096"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# 1) Load train.csv and filter by FAMILY\n",
    "df_train_all = pd.read_csv(TRAIN_CSV, parse_dates=[\"date\"])\n",
    "df_train = df_train_all[df_train_all[\"family\"] == FAMILY].copy()\n",
    "if df_train.empty:\n",
    "    raise ValueError(f\"No rows found for family '{FAMILY}' in {TRAIN_CSV}\")\n",
    "\n",
    "# 2) Load test.csv and filter by FAMILY\n",
    "df_test_all = pd.read_csv(TEST_CSV, parse_dates=[\"date\"])\n",
    "df_test = df_test_all[df_test_all[\"family\"] == FAMILY].copy()\n",
    "if df_test.empty:\n",
    "    print(f\"Warning: No rows found for family '{FAMILY}' in {TEST_CSV}. Forecasting will be skipped.\")\n",
    "\n",
    "# 3) Aggregate train by date (sum sales + onpromotion across all stores)\n",
    "df_train_agg = (\n",
    "    df_train\n",
    "    .groupby(\"date\")[[\"sales\", \"onpromotion\"]]\n",
    "    .sum()\n",
    "    .rename(columns={\"onpromotion\": \"onpromo\"})\n",
    "    .sort_index()\n",
    ")\n",
    "\n",
    "# 4) Convert to PeriodIndex (daily) and fill missing dates with zeros\n",
    "df_train_agg.index = pd.DatetimeIndex(df_train_agg.index).to_period(FREQ)\n",
    "df_train_agg = df_train_agg.asfreq(FREQ)\n",
    "df_train_agg[\"sales\"]   = df_train_agg[\"sales\"].fillna(0).astype(float)\n",
    "df_train_agg[\"onpromo\"] = df_train_agg[\"onpromo\"].fillna(0).astype(float)\n",
    "\n",
    "# 5) Remove rows where sales == 0\n",
    "orig_len = len(df_train_agg)\n",
    "df_train_agg = df_train_agg[df_train_agg[\"sales\"] != 0].copy()\n",
    "print(f\"Removed {orig_len - len(df_train_agg)} zero-sales rows → {len(df_train_agg)} remaining\")\n",
    "\n",
    "# 6) Check if enough points remain\n",
    "if len(df_train_agg) < (N_VALID + 1):\n",
    "    raise ValueError(f\"Not enough data points ({len(df_train_agg)}) for hold-out of {N_VALID} days.\")\n",
    "\n",
    "# 7) Split hold-out (if N_VALID > 0)\n",
    "if N_VALID > 0:\n",
    "    df_valid_holdout = df_train_agg.iloc[-N_VALID:]\n",
    "    df_train_series  = df_train_agg.iloc[:-N_VALID]\n",
    "    print(f\"Held out last {N_VALID} days for validation.\")\n",
    "else:\n",
    "    df_valid_holdout = None\n",
    "    df_train_series  = df_train_agg\n",
    "\n",
    "# 8) Stationarity test on raw sales\n",
    "print(\"\\nRunning ADF test on training 'sales' series:\")\n",
    "test_stationarity(df_train_series[\"sales\"], name=\"sales\")\n",
    "\n",
    "# 9) Log-transform the training sales\n",
    "df_train_series[\"y_log\"] = np.log1p(df_train_series[\"sales\"])\n",
    "\n",
    "# 10) Prepare exogenous arrays and scale them\n",
    "exog_train_raw = df_train_series[\"onpromo\"].values.reshape(-1, 1)\n",
    "if df_valid_holdout is not None:\n",
    "    exog_valid_raw = df_valid_holdout[\"onpromo\"].values.reshape(-1, 1)\n",
    "\n",
    "scaler = StandardScaler()\n",
    "exog_train_scaled = scaler.fit_transform(exog_train_raw).ravel()\n",
    "exog_train = pd.Series(exog_train_scaled, index=df_train_series.index)\n",
    "\n",
    "if df_valid_holdout is not None:\n",
    "    exog_valid_scaled = scaler.transform(exog_valid_raw).ravel()\n",
    "    exog_valid = pd.Series(exog_valid_scaled, index=df_valid_holdout.index)\n",
    "else:\n",
    "    exog_valid = None\n",
    "\n",
    "# 11) Run auto_arima for order selection\n",
    "print(\"\\nRunning auto_arima for hyperparameter tuning:\")\n",
    "mi = auto_arima(\n",
    "    df_train_series[\"y_log\"],\n",
    "    exogenous=exog_train.values.reshape(-1, 1),\n",
    "    **AUTO_ARIMA_ARGS\n",
    ")\n",
    "order_opt          = mi.order\n",
    "seasonal_order_opt = mi.seasonal_order\n",
    "print(f\"Selected order = {order_opt}, seasonal_order = {seasonal_order_opt}\")\n",
    "\n",
    "# 12) Fit SARIMAX on the training series\n",
    "print(\"\\nFitting SARIMAX on log-transformed series with scaled exogenous:\")\n",
    "model = SARIMAX(\n",
    "    df_train_series[\"y_log\"],\n",
    "    exog=exog_train,\n",
    "    order=order_opt,\n",
    "    seasonal_order=seasonal_order_opt,\n",
    "    enforce_stationarity=False,\n",
    "    enforce_invertibility=False\n",
    ")\n",
    "sarimax_fit = model.fit(disp=False)\n",
    "print(sarimax_fit.summary())\n",
    "\n",
    "# 13) Evaluate hold-out performance (if applicable)\n",
    "if df_valid_holdout is not None:\n",
    "    print(\"\\nComputing hold-out metrics:\")\n",
    "    pred_log_valid = sarimax_fit.get_forecast(\n",
    "        steps=N_VALID,\n",
    "        exog=exog_valid.values.reshape(-1, 1)\n",
    "    ).predicted_mean\n",
    "    actual_valid = df_valid_holdout[\"sales\"].values\n",
    "    pred_valid   = np.expm1(\n",
    "        sarimax_fit\n",
    "            .get_forecast(steps=N_VALID, exog=exog_valid.values.reshape(-1, 1))\n",
    "            .predicted_mean\n",
    "    )\n",
    "\n",
    "    rmse_val = np.sqrt(mean_squared_error(actual_valid, pred_valid))\n",
    "    mae_val  = mean_absolute_error(actual_valid, pred_valid)\n",
    "    r2_val   = r2_score(actual_valid, pred_valid)\n",
    "    mape_val = np.mean(np.abs((actual_valid - pred_valid) / actual_valid)) * 100\n",
    "    \n",
    "    print(f\"Hold‐out metrics:\")\n",
    "    print(f\"  RMSE = {rmse_val:.2f}\")\n",
    "    print(f\"   MAE = {mae_val:.2f}\")\n",
    "    print(f\"    R² = {r2_val:.3f}\")\n",
    "    print(f\"  MAPE = {mape_val:.2f}%\")\n",
    "\n",
    "    # Save hold-out performance to CSV\n",
    "    perf_df = pd.DataFrame([{\n",
    "        \"family\": FAMILY,\n",
    "        \"RMSE\": rmse_val,\n",
    "        \"MAE\": mae_val,\n",
    "        \"R2\": r2_val,\n",
    "        \"MAPE\": mape_val\n",
    "    }])\n",
    "    perf_df.to_csv(PERF_CSV, index=False)\n",
    "    print(f\"Hold-out performance saved to {PERF_CSV}\")\n",
    "\n",
    "# 14) Forecast on test dates (if test data exists)\n",
    "if not df_test.empty:\n",
    "    # Aggregate test exogenous by date\n",
    "    df_test[\"date\"] = pd.to_datetime(df_test[\"date\"])\n",
    "    agg_exog_test = (\n",
    "        df_test\n",
    "        .groupby(\"date\")[[\"onpromotion\"]]\n",
    "        .sum()\n",
    "        .rename(columns={\"onpromotion\": \"onpromo\"})\n",
    "    )\n",
    "    agg_exog_test.index = pd.DatetimeIndex(agg_exog_test.index).to_period(FREQ)\n",
    "    agg_exog_test = agg_exog_test.asfreq(FREQ, fill_value=0)\n",
    "\n",
    "    # Scale test exogenous\n",
    "    exog_test_raw   = agg_exog_test[\"onpromo\"].values.reshape(-1, 1)\n",
    "    exog_test_scaled = scaler.transform(exog_test_raw).ravel()\n",
    "\n",
    "    # Forecast\n",
    "    h = len(agg_exog_test)\n",
    "    print(f\"\\nForecasting {h} future points on test set:\")\n",
    "    pred_log_test  = sarimax_fit.get_forecast(\n",
    "        steps=h,\n",
    "        exog=exog_test_scaled.reshape(-1, 1)\n",
    "    ).predicted_mean\n",
    "    pred_sales_test = np.expm1(pred_log_test)\n",
    "\n",
    "    # Build a date-level forecast DataFrame\n",
    "    df_forecast_dates = pd.DataFrame({\n",
    "        \"date\": agg_exog_test.index.to_timestamp(),\n",
    "        \"predicted_sales\": pred_sales_test\n",
    "    })\n",
    "\n",
    "    # Merge date-level predictions back onto every row of df_test\n",
    "    df_test = df_test.merge(\n",
    "        df_forecast_dates,\n",
    "        left_on=\"date\",\n",
    "        right_on=\"date\",\n",
    "        how=\"left\"\n",
    "    )\n",
    "\n",
    "    # Prepare final forecast output (one row per original test id)\n",
    "    df_forecast_output = pd.DataFrame({\n",
    "        \"id\": df_test[\"id\"].values,\n",
    "        \"date\": df_test[\"date\"].values,\n",
    "        \"store_nbr\": df_test[\"store_nbr\"].values,\n",
    "        \"family\": FAMILY,\n",
    "        \"predicted_sales\": df_test[\"predicted_sales\"].values\n",
    "    })\n",
    "\n",
    "    # Save to CSV\n",
    "    df_forecast_output.to_csv(FORECAST_CSV, index=False)\n",
    "    print(f\"Forecasts saved to {FORECAST_CSV}\")\n",
    "    display(df_forecast_output.head(10))\n",
    "else:\n",
    "    print(\"\\nNo test data for this family; skipping forecast step.\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "tf-gpu",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.22"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
